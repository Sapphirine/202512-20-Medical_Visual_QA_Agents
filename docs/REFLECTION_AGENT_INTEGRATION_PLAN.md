# Reflection Agent é›†æˆè®¡åˆ’

> **ç›®æ ‡**: å°† `reflection_agent.py` é›†æˆåˆ° `medical_assistant_agent.py` ä¸» Agent ä¸­ï¼Œå®ç° ACE (Agentic Context Engineering) çš„è‡ªæˆ‘æ”¹è¿›é—­ç¯ã€‚

---

## ğŸ†• Playbook Prompt åŠ¨æ€æ³¨å…¥æ–¹æ¡ˆ

> **ç”¨æˆ·é—®é¢˜**: å¦‚ä½•å°† `data/ace_memory/playbook.md` çš„å†…å®¹åŠ¨æ€æ³¨å…¥åˆ° medical agent çš„ system prompt ä¸­ï¼Ÿ

æ ¹æ® LangChain å®˜æ–¹æ–‡æ¡£ï¼Œæœ‰ä»¥ä¸‹ä¸‰ç§æ¨èæ–¹æ¡ˆï¼š

### æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | å¤æ‚åº¦ | å®æ—¶æ€§ | é€‚ç”¨åœºæ™¯ | æ–‡æ¡£æ¥æº |
|------|--------|--------|----------|----------|
| **A. f-string åŠ¨æ€è¯»å–** | â­ ç®€å• | æ¯æ¬¡è°ƒç”¨æ—¶è¯»å– | å¿«é€ŸåŸå‹ | LangGraph quickstart |
| **B. Middleware wrap_model_call** | â­â­ ä¸­ç­‰ | æ‹¦æˆªæ¯æ¬¡ LLM è°ƒç”¨ | ç”Ÿäº§æ¨è | [context-engineering](https://docs.langchain.com/oss/python/langchain/context-engineering) |
| **C. LangSmith Store** | â­â­â­ å¤æ‚ | æŒä¹…åŒ–å­˜å‚¨ | å¤š agent å…±äº« | [context-engineering](https://docs.langchain.com/oss/python/langchain/context-engineering) |

---

### æ–¹æ¡ˆ A: f-string åŠ¨æ€è¯»å– (æ¨èå¼€å§‹ä½¿ç”¨)

æœ€ç®€å•ç›´æ¥çš„æ–¹å¼ï¼Œåœ¨ `call_model` èŠ‚ç‚¹ä¸­åŠ¨æ€è¯»å– playbook æ–‡ä»¶ï¼š

```python
# åœ¨ medical_assistant_agent.py ä¸­ä¿®æ”¹

import os

# Playbook è·¯å¾„
ACE_PLAYBOOK_PATH = os.path.join(
    os.path.dirname(__file__), 
    "../../data/ace_memory/playbook.md"
)

def get_playbook_content() -> str:
    """åŠ¨æ€è¯»å– playbook å†…å®¹"""
    try:
        with open(ACE_PLAYBOOK_PATH, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return "# No playbook available yet."

# ä¿®æ”¹ SYSTEM_PROMPT ä¸ºåŠ¨æ€å‡½æ•°
def get_system_prompt() -> str:
    playbook = get_playbook_content()
    return f"""You are a helpful medical imaging assistant powered by AI.

You have access to a powerful medical visual question answering (VQA) tool...

[åŸæœ‰çš„ SYSTEM_PROMPT å†…å®¹...]

---

## ACE Strategy Playbook (åŠ¨æ€æ›´æ–°)

ä»¥ä¸‹æ˜¯ä»æ‰§è¡Œç»éªŒä¸­å­¦åˆ°çš„ç­–ç•¥ï¼Œè¯·å‚è€ƒè¿™äº›ç­–ç•¥åšå‡ºæ›´å¥½çš„å†³ç­–ï¼š

{playbook}

---
"""

# ä¿®æ”¹ call_model å‡½æ•°
def call_model(state: AgentState, config: RunnableConfig):
    messages = state["messages"]
    # æ¯æ¬¡è°ƒç”¨æ—¶åŠ¨æ€è·å–æœ€æ–°çš„ system prompt
    system_msg = SystemMessage(content=get_system_prompt())
    chain_input = [system_msg] + messages
    
    response = model_with_tools.invoke(chain_input, config)
    return {"messages": [response]}
```

**ä¼˜ç‚¹**: 
- å®ç°ç®€å•ï¼Œæ— éœ€é¢å¤–ä¾èµ–
- æ¯æ¬¡ LLM è°ƒç”¨éƒ½è·å–æœ€æ–°çš„ playbook
- ä¸ç°æœ‰ä»£ç ç»“æ„å…¼å®¹

**ç¼ºç‚¹**:
- æ–‡ä»¶ I/O åœ¨æ¯æ¬¡è°ƒç”¨æ—¶å‘ç”Ÿ
- æ²¡æœ‰ç¼“å­˜æœºåˆ¶

---

### æ–¹æ¡ˆ B: Middleware wrap_model_call (ç”Ÿäº§æ¨è)

ä½¿ç”¨ LangChain v1 çš„ middleware æ¨¡å¼ï¼Œæ›´ä¼˜é›…åœ°æ³¨å…¥ä¸Šä¸‹æ–‡ï¼š

```python
# æ–‡æ¡£æ¥æº: https://docs.langchain.com/oss/python/langchain/context-engineering

from langchain.agents import create_agent
from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse
from typing import Callable

ACE_PLAYBOOK_PATH = "./data/ace_memory/playbook.md"

@wrap_model_call
def inject_playbook_context(
    request: ModelRequest,
    handler: Callable[[ModelRequest], ModelResponse]
) -> ModelResponse:
    """
    æ‹¦æˆªæ¯æ¬¡ LLM è°ƒç”¨ï¼Œæ³¨å…¥ playbook ä¸Šä¸‹æ–‡ã€‚
    
    æ–‡æ¡£å‚è€ƒ: https://docs.langchain.com/oss/python/langchain/context-engineering
    """
    # è¯»å– playbook
    try:
        with open(ACE_PLAYBOOK_PATH, "r") as f:
            playbook_content = f.read()
    except FileNotFoundError:
        playbook_content = "No strategies available."
    
    # æ„å»ºæ³¨å…¥æ¶ˆæ¯
    playbook_message = {
        "role": "system",
        "content": f"""
## ACE Strategy Playbook

The following strategies were learned from past executions. 
Use them to guide your decisions:

{playbook_content}
"""
    }
    
    # å°† playbook æ·»åŠ åˆ°æ¶ˆæ¯æœ«å°¾ (LLM æ›´å…³æ³¨æœ«å°¾å†…å®¹)
    messages = [*request.messages, playbook_message]
    request = request.override(messages=messages)
    
    return handler(request)

# ä½¿ç”¨ middleware åˆ›å»º agent
agent = create_agent(
    model="gpt-4o",
    tools=[medical_vqa_tool],
    middleware=[inject_playbook_context]  # æ·»åŠ  middleware
)
```

**ä¼˜ç‚¹**:
- éµå¾ª LangChain æœ€ä½³å®è·µ
- å…³æ³¨ç‚¹åˆ†ç¦»ï¼šprompt é€»è¾‘ä¸ä¸šåŠ¡é€»è¾‘è§£è€¦
- å¯ç»„åˆå¤šä¸ª middleware

**ç¼ºç‚¹**:
- éœ€è¦ LangChain v1 / langchain-agents åº“
- è¯­æ³•ä¸å½“å‰ LangGraph StateGraph æ¨¡å¼ä¸åŒ

---

### æ–¹æ¡ˆ C: LangSmith Store (é«˜çº§)

ä½¿ç”¨ LangGraph Store æŒä¹…åŒ– playbookï¼Œæ”¯æŒè·¨ session å’Œå¤š agent å…±äº«ï¼š

```python
# æ–‡æ¡£æ¥æº: https://docs.langchain.com/oss/python/langchain/context-engineering

from langgraph.store.memory import InMemoryStore
from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse
from typing import Callable

@wrap_model_call
def inject_playbook_from_store(
    request: ModelRequest,
    handler: Callable[[ModelRequest], ModelResponse]
) -> ModelResponse:
    """
    ä» LangGraph Store è¯»å– playbookã€‚
    """
    store = request.runtime.store  # è®¿é—® Store
    
    # ä» Store è·å– playbook
    playbook_item = store.get(("ace",), "playbook")
    
    if playbook_item:
        playbook_content = playbook_item.value.get("content", "")
        
        # æ³¨å…¥åˆ°æ¶ˆæ¯ä¸­
        messages = [
            *request.messages,
            {"role": "system", "content": f"## Strategy Playbook\n{playbook_content}"}
        ]
        request = request.override(messages=messages)
    
    return handler(request)

# åˆ›å»º Store å¹¶åˆå§‹åŒ– playbook
store = InMemoryStore()

# è¯»å–æ–‡ä»¶å¹¶å­˜å…¥ Store
with open("./data/ace_memory/playbook.md", "r") as f:
    store.put(("ace",), "playbook", {"content": f.read()})

# åˆ›å»º agent
agent = create_agent(
    model="gpt-4o",
    tools=[...],
    middleware=[inject_playbook_from_store],
    store=store
)
```

**ä¼˜ç‚¹**:
- æ”¯æŒè¯­ä¹‰æœç´¢ (å¦‚æœå¯ç”¨ index)
- å¯è·¨ thread/session å…±äº«
- åæ€ agent å¯ä»¥ç›´æ¥æ›´æ–° Store

**ç¼ºç‚¹**:
- éœ€è¦é¢å¤–çš„ Store åŸºç¡€è®¾æ–½
- å¼•å…¥çŠ¶æ€åŒæ­¥å¤æ‚æ€§

---

### ğŸ¯ æ¨èå®ç°è·¯å¾„

1. **Phase 1 (ç°åœ¨)**: ä½¿ç”¨ **æ–¹æ¡ˆ A** - f-string åŠ¨æ€è¯»å–
   - æœ€å¿«å®ç°ï¼Œç«‹å³å¯ç”¨
   - ä¸ç°æœ‰ LangGraph StateGraph å®Œå…¨å…¼å®¹

2. **Phase 2 (ä¼˜åŒ–)**: æ·»åŠ ç¼“å­˜æœºåˆ¶
   ```python
   import functools
   import time
   
   @functools.lru_cache(maxsize=1)
   def get_playbook_cached(mtime: float) -> str:
       with open(ACE_PLAYBOOK_PATH, "r") as f:
           return f.read()
   
   def get_playbook_content() -> str:
       mtime = os.path.getmtime(ACE_PLAYBOOK_PATH)
       return get_playbook_cached(mtime)
   ```

3. **Phase 3 (ç”Ÿäº§)**: è¿ç§»åˆ° **æ–¹æ¡ˆ B** middleware æ¨¡å¼

---

## 1. ç°çŠ¶åˆ†æ

### 1.1 ä¸» Agent (`medical_assistant_agent.py`)
- **æ¡†æ¶**: LangGraph StateGraph
- **State ç»“æ„**:
  ```python
  class AgentState(TypedDict):
      messages: Annotated[List[BaseMessage], add_messages]
      _uploaded_image_path: Union[str, None]
  ```
- **èŠ‚ç‚¹**: `preprocess` â†’ `agent` â†’ `tools` (å¾ªç¯)
- **éƒ¨ç½²**: é€šè¿‡ `langgraph.json` æš´éœ²ä¸º `medical_assistant`

### 1.2 Reflection Agent (`reflection_agent.py`)
- **æ¡†æ¶**: `deepagents` åº“ (åŸºäº LangGraph)
- **åŠŸèƒ½**: åˆ†ææ‰§è¡Œ traceï¼Œæ›´æ–° `data/ace_memory/playbook.md`
- **æ¥å£**: `process_trace_background(trace_data: str)` - å¼‚æ­¥å‡½æ•°

---

## 2. é›†æˆæ–¹æ¡ˆå¯¹æ¯” (åŸºäº LangChain å®˜æ–¹æ–‡æ¡£)

æ ¹æ® LangGraph æ–‡æ¡£ï¼Œæœ‰ä¸‰ç§ä¸»è¦é›†æˆæ–¹å¼ï¼š

| æ–¹æ¡ˆ | æè¿° | ä¼˜ç‚¹ | ç¼ºç‚¹ | æ–‡æ¡£æ¥æº |
|------|------|------|------|----------|
| **A. Subgraph èŠ‚ç‚¹è°ƒç”¨** | åœ¨çˆ¶å›¾èŠ‚ç‚¹å†…è°ƒç”¨å­å›¾ | å®Œå…¨æ§åˆ¶ state è½¬æ¢ | åŒæ­¥æ‰§è¡Œï¼Œä¼šé˜»å¡ä¸»æµç¨‹ | [use-subgraphs](https://docs.langchain.com/oss/python/langgraph/use-subgraphs) |
| **B. asyncio.create_task** | Fire-and-forget åå°ä»»åŠ¡ | ä¸é˜»å¡ä¸»æµç¨‹ | ä¸ä¸ LangGraph state ç›´æ¥ç»‘å®š | Python asyncio æ ‡å‡†æ¨¡å¼ |
| **C. LangSmith Background Run** | é€šè¿‡ webhook è§¦å‘åå°è¿è¡Œ | ç”Ÿäº§çº§ã€å¯ç›‘æ§ | éœ€è¦ LangSmith éƒ¨ç½² | [create-background-run](https://docs.langchain.com/langsmith/agent-server-api/thread-runs/create-background-run) |

### æ¨èæ–¹æ¡ˆ: **æ–¹æ¡ˆ B + C ç»„åˆ**
- **å¼€å‘é˜¶æ®µ**: ä½¿ç”¨ `asyncio.create_task` å®ç°æœ¬åœ° fire-and-forget
- **ç”Ÿäº§é˜¶æ®µ**: è¿ç§»åˆ° LangSmith Background Runs + Webhooks

---

## 3. è¯¦ç»†å®ç°è®¡åˆ’

### 3.1 Phase 1: çŠ¶æ€æ‰©å±•

**ç›®æ ‡**: æ‰©å±• `AgentState` ä»¥æ”¯æŒ trace æ”¶é›†

```python
# åœ¨ medical_assistant_agent.py ä¸­ä¿®æ”¹

from typing import Annotated, TypedDict, Union, List, Dict, Any, Optional
import operator

class AgentState(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]
    _uploaded_image_path: Union[str, None]
    # æ–°å¢: ç”¨äº ACE åæ€çš„ trace æ•°æ®
    _execution_trace: Optional[str]  # æ”¶é›†çš„æ‰§è¡Œè½¨è¿¹
    _reflection_triggered: bool  # æ˜¯å¦å·²è§¦å‘åæ€
```

### 3.2 Phase 2: Trace æ”¶é›†èŠ‚ç‚¹

**ç›®æ ‡**: åœ¨ agent æ‰§è¡Œç»“æŸæ—¶æ”¶é›† trace

```python
# æ–°å¢èŠ‚ç‚¹å‡½æ•°

def collect_trace(state: AgentState) -> Dict[str, Any]:
    """
    æ”¶é›†æ‰§è¡Œè½¨è¿¹ç”¨äºåæ€ã€‚
    åœ¨å›¾çš„ END ä¹‹å‰è¿è¡Œã€‚
    """
    messages = state["messages"]
    
    # æ„å»º trace å­—ç¬¦ä¸²
    trace_parts = []
    for msg in messages:
        role = getattr(msg, 'type', 'unknown')
        content = getattr(msg, 'content', '')[:500]  # æˆªæ–­è¿‡é•¿å†…å®¹
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ tool calls
        tool_calls = getattr(msg, 'tool_calls', [])
        if tool_calls:
            tool_info = ", ".join([tc.get('name', 'unknown') for tc in tool_calls])
            trace_parts.append(f"{role}: [Tool Calls: {tool_info}] {content}")
        else:
            trace_parts.append(f"{role}: {content}")
    
    execution_trace = "\n".join(trace_parts)
    
    return {
        "_execution_trace": execution_trace,
        "_reflection_triggered": False  # æ ‡è®°å°šæœªè§¦å‘
    }
```

### 3.3 Phase 3: Fire-and-Forget åæ€è§¦å‘

**ç›®æ ‡**: åå°è§¦å‘ reflection agentï¼Œä¸é˜»å¡ä¸»æµç¨‹

#### æ–¹å¼ A: ä½¿ç”¨ asyncio (å¼€å‘é˜¶æ®µæ¨è)

```python
import asyncio
from src.agents.reflection_agent import process_trace_background

# å…¨å±€ä»»åŠ¡è¿½è¸ªå™¨ (å¯é€‰ï¼Œç”¨äºç›‘æ§)
_background_tasks = set()

async def trigger_reflection_async(trace_data: str):
    """
    Fire-and-forget åå°åæ€ä»»åŠ¡ã€‚
    """
    try:
        result = await process_trace_background(trace_data)
        print(f"[ACE Reflection] Completed: {result[:100]}...")
    except Exception as e:
        print(f"[ACE Reflection] Error: {e}")
    finally:
        # æ¸…ç†ä»»åŠ¡å¼•ç”¨
        pass

def trigger_reflection_node(state: AgentState) -> Dict[str, Any]:
    """
    è§¦å‘åå°åæ€çš„èŠ‚ç‚¹ã€‚
    ä½¿ç”¨ asyncio.create_task å®ç° fire-and-forgetã€‚
    """
    trace = state.get("_execution_trace", "")
    
    if not trace or state.get("_reflection_triggered", False):
        return {"_reflection_triggered": True}
    
    # è·å–å½“å‰äº‹ä»¶å¾ªç¯
    try:
        loop = asyncio.get_running_loop()
        # åˆ›å»ºåå°ä»»åŠ¡ (fire-and-forget)
        task = loop.create_task(trigger_reflection_async(trace))
        _background_tasks.add(task)
        task.add_done_callback(_background_tasks.discard)
    except RuntimeError:
        # å¦‚æœæ²¡æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œä½¿ç”¨çº¿ç¨‹æ± 
        import concurrent.futures
        executor = concurrent.futures.ThreadPoolExecutor(max_workers=1)
        executor.submit(asyncio.run, trigger_reflection_async(trace))
    
    return {"_reflection_triggered": True}
```

#### æ–¹å¼ B: ä½¿ç”¨ Webhook (ç”Ÿäº§é˜¶æ®µ)

```python
# å‚è€ƒ LangSmith æ–‡æ¡£:
# https://docs.langchain.com/langsmith/use-webhooks

import httpx

async def trigger_reflection_via_webhook(trace_data: str):
    """
    é€šè¿‡ webhook è§¦å‘ LangSmith åå°è¿è¡Œã€‚
    """
    webhook_url = "https://your-deployment/api/reflection/trigger"
    
    async with httpx.AsyncClient() as client:
        await client.post(
            webhook_url,
            json={"trace": trace_data},
            timeout=5.0  # å¿«é€Ÿè¿”å›ï¼Œä¸ç­‰å¾…å®Œæˆ
        )
```

### 3.4 Phase 4: å›¾ç»“æ„æ›´æ–°

**ç›®æ ‡**: å°†æ–°èŠ‚ç‚¹é›†æˆåˆ°å›¾ä¸­

```python
# æ›´æ–°åçš„å›¾ç»“æ„

from langgraph.graph import StateGraph, END, START

builder = StateGraph(AgentState)

# ç°æœ‰èŠ‚ç‚¹
builder.add_node("preprocess", preprocess_state)
builder.add_node("agent", call_model)
builder.add_node("tools", custom_tool_node)

# æ–°å¢èŠ‚ç‚¹
builder.add_node("collect_trace", collect_trace)
builder.add_node("trigger_reflection", trigger_reflection_node)

# è¾¹å®šä¹‰
builder.set_entry_point("preprocess")
builder.add_edge("preprocess", "agent")

def should_continue(state: AgentState):
    messages = state["messages"]
    last_message = messages[-1]
    if last_message.tool_calls:
        return "tools"
    return "collect_trace"  # ä¿®æ”¹: ä¸ç›´æ¥ END

builder.add_conditional_edges("agent", should_continue)
builder.add_edge("tools", "agent")

# æ–°å¢: åæ€æµç¨‹
builder.add_edge("collect_trace", "trigger_reflection")
builder.add_edge("trigger_reflection", END)

agent = builder.compile()
```

### 3.5 å›¾ç»“æ„å¯è§†åŒ–

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   preprocess    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”Œâ”€â”€â”€â”€â”€â”€â–¶â”‚     agent       â”‚â—€â”€â”€â”€â”€â”€â”
            â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
            â”‚                â”‚               â”‚
            â”‚       has_tool_calls?          â”‚
            â”‚         /          \           â”‚
            â”‚       yes           no         â”‚
            â”‚        â”‚             â”‚         â”‚
            â”‚        â–¼             â–¼         â”‚
            â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  â”‚  tools   â”‚  â”‚  collect_trace  â”‚
            â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚       â”‚                 â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”˜                 â–¼
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚ trigger_reflection  â”‚ (Fire-and-Forget)
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                                   [END]
```

---

## 4. å¦‚ä½•è·å– State (å…³é”®æ–‡æ¡£å‚è€ƒ)

æ ¹æ® LangGraph å®˜æ–¹æ–‡æ¡£ï¼Œåœ¨èŠ‚ç‚¹ä¸­è·å– state çš„æ–¹å¼ï¼š

### 4.1 èŠ‚ç‚¹å‡½æ•°å‚æ•°

```python
# æ–‡æ¡£æ¥æº: https://docs.langchain.com/oss/python/langgraph/graph-api

def my_node(state: AgentState, config: RunnableConfig) -> Dict[str, Any]:
    """
    èŠ‚ç‚¹å‡½æ•°çš„ç¬¬ä¸€ä¸ªå‚æ•°å§‹ç»ˆæ˜¯ stateã€‚
    
    Args:
        state: å½“å‰å›¾çš„å®Œæ•´çŠ¶æ€
        config: åŒ…å« thread_idã€tags ç­‰é…ç½®ä¿¡æ¯
    
    Returns:
        çŠ¶æ€æ›´æ–°å­—å…¸ (ä¸æ˜¯å®Œæ•´ stateï¼Œåªæ˜¯å¢é‡æ›´æ–°)
    """
    # è¯»å– state
    messages = state["messages"]
    uploaded_path = state.get("_uploaded_image_path")
    
    # è¿”å›æ›´æ–° (åªåŒ…å«è¦æ›´æ–°çš„é”®)
    return {
        "_execution_trace": "some trace data"
    }
```

### 4.2 åœ¨ Subgraph ä¸­ä¼ é€’ State

```python
# æ–‡æ¡£æ¥æº: https://docs.langchain.com/oss/python/langgraph/use-subgraphs

def invoke_subgraph_node(state: ParentState) -> Dict[str, Any]:
    """
    åœ¨çˆ¶å›¾èŠ‚ç‚¹ä¸­è°ƒç”¨å­å›¾ã€‚
    éœ€è¦æ‰‹åŠ¨è¿›è¡Œ state è½¬æ¢ã€‚
    """
    # è½¬æ¢åˆ°å­å›¾ state
    subgraph_input = {"bar": state["foo"]}
    
    # è°ƒç”¨å­å›¾
    subgraph_output = subgraph.invoke(subgraph_input)
    
    # è½¬æ¢å›çˆ¶å›¾ state
    return {"foo": subgraph_output["bar"]}
```

### 4.3 é€šè¿‡ Config è·å–å…ƒæ•°æ®

```python
# æ–‡æ¡£æ¥æº: https://docs.langchain.com/oss/javascript/langgraph/graph-api

def my_node(state: AgentState, config: RunnableConfig) -> Dict[str, Any]:
    # è·å–å½“å‰æ­¥éª¤æ•°
    current_step = config.get("metadata", {}).get("langgraph_step", 0)
    
    # è·å– thread_id
    thread_id = config.get("configurable", {}).get("thread_id")
    
    return state
```

---

## 5. å¯é€‰å¢å¼º: ä½¿ç”¨ deepagents SubAgentMiddleware

æ ¹æ® deepagents æ–‡æ¡£ï¼Œå¯ä»¥ä½¿ç”¨ SubAgentMiddleware å®ç°æ›´ä¼˜é›…çš„å­ agent é›†æˆï¼š

```python
# æ–‡æ¡£æ¥æº: https://docs.langchain.com/oss/python/deepagents/middleware

from deepagents.middleware.subagents import SubAgentMiddleware

# å®šä¹‰ reflection ä½œä¸º subagent
reflection_subagent = {
    "name": "ace_reflector",
    "description": "Analyzes execution traces and updates the strategy playbook",
    "system_prompt": REFLECTION_SYSTEM_PROMPT,
    "tools": []  # ä½¿ç”¨ FilesystemBackend
}

# åœ¨ä¸» agent åˆ›å»ºæ—¶æ·»åŠ  middleware
agent = create_deep_agent(
    model=llm,
    system_prompt=MAIN_SYSTEM_PROMPT,
    middleware=[
        SubAgentMiddleware(subagents=[reflection_subagent])
    ]
)
```

**æ³¨æ„**: æ­¤æ–¹æ¡ˆéœ€è¦å°†ä¸» agent è¿ç§»åˆ° deepagents æ¡†æ¶ï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚

---

## 6. å®æ–½æ£€æŸ¥æ¸…å•

- [ ] **Phase 1**: æ‰©å±• `AgentState` TypedDict
- [ ] **Phase 2**: å®ç° `collect_trace` èŠ‚ç‚¹å‡½æ•°
- [ ] **Phase 3**: å®ç° `trigger_reflection_node` èŠ‚ç‚¹å‡½æ•°
- [ ] **Phase 4**: æ›´æ–°å›¾ç»“æ„ (edges)
- [ ] **Phase 5**: æµ‹è¯• fire-and-forget è¡Œä¸º
- [ ] **Phase 6**: éªŒè¯ playbook.md æ›´æ–°
- [ ] **Phase 7**: (ç”Ÿäº§) è¿ç§»åˆ° LangSmith Background Runs

---

## 7. é£é™©ä¸æ³¨æ„äº‹é¡¹

1. **äº‹ä»¶å¾ªç¯å†²çª**: `langgraph dev` å·²æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œéœ€ä½¿ç”¨ `loop.create_task()` è€Œé `asyncio.run()`
2. **State éš”ç¦»**: reflection agent ä¸åº”ä¿®æ”¹ä¸» agent çš„ state
3. **é”™è¯¯å¤„ç†**: åå°ä»»åŠ¡çš„å¼‚å¸¸ä¸åº”å½±å“ä¸»æµç¨‹
4. **èµ„æºæ³„æ¼**: ä½¿ç”¨ `task.add_done_callback()` æ¸…ç†ä»»åŠ¡å¼•ç”¨
5. **trace å¤§å°**: æˆªæ–­è¿‡é•¿çš„ message content é¿å… token æº¢å‡º

---

## 8. å‚è€ƒæ–‡æ¡£é“¾æ¥

| ä¸»é¢˜ | é“¾æ¥ |
|------|------|
| LangGraph Subgraphs | https://docs.langchain.com/oss/python/langgraph/use-subgraphs |
| LangGraph Graph API | https://docs.langchain.com/oss/python/langgraph/graph-api |
| LangGraph State & Reducers | https://docs.langchain.com/oss/python/langgraph/use-graph-api |
| LangSmith Background Runs | https://docs.langchain.com/langsmith/agent-server-api/thread-runs/create-background-run |
| LangSmith Webhooks | https://docs.langchain.com/langsmith/use-webhooks |
| Deep Agents Middleware | https://docs.langchain.com/oss/python/deepagents/middleware |
| Deep Agents SubAgent | https://docs.langchain.com/oss/javascript/deepagents/harness |

---

*ç”Ÿæˆæ—¥æœŸ: 2025-12-12*
*åŸºäº LangGraph v1 æ–‡æ¡£*
