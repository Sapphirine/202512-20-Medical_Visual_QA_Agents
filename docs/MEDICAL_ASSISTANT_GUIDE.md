# Medical Assistant Agent ä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

Medical Assistant Agent æ˜¯ä¸€ä¸ªæ™ºèƒ½åŒ»å­¦å›¾åƒåˆ†æåŠ©æ‰‹ï¼Œç»“åˆäº†ï¼š
- ğŸ¤– **GPT-4.1** è¯­è¨€æ¨¡å‹
- ğŸ‘ï¸ **å¤šæ¨¡æ€è§†è§‰-è¯­è¨€æ¨¡å‹** (CLIP + TinyLlama + Projector)
- ğŸ”§ **LangChain ReAct Agent** æ¡†æ¶

## æ¶æ„

```
Medical-ACE/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ medical_assistant_agent.py  # ä¸» Agent
â”‚   â”‚   â””â”€â”€ reflection_agent.py         # ACE åæ€ Agent
â”‚   â””â”€â”€ tools/
â”‚       â””â”€â”€ medical_vqa_tool.py         # åŒ»å­¦ VQA å·¥å…·
â”œâ”€â”€ inference.py                         # å¤šæ¨¡æ€æ¨ç†å¼•æ“
â”œâ”€â”€ main.py                             # ä¸»ç¨‹åºå…¥å£
â””â”€â”€ projector_epoch2.pt                 # è®­ç»ƒå¥½çš„æŠ•å½±å™¨
```

## å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒé…ç½®

ç¡®ä¿ `.env` æ–‡ä»¶åŒ…å«ï¼š

```bash
OPENAI_API_KEY=your_openai_api_key
LANGSMITH_API_KEY=your_langsmith_api_key  # å¯é€‰ï¼Œç”¨äºè¿½è¸ª
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=Medical-ACE
```

### 2. å®‰è£…ä¾èµ–

```bash
conda activate ACE
pip install -r requirements.txt
```

### 3. è¿è¡Œæ–¹å¼

#### æ–¹å¼ 1ï¼šå•æ¬¡æŸ¥è¯¢ï¼ˆæ¨èç”¨äºæµ‹è¯•ï¼‰

```bash
python main.py --mode single
```

#### æ–¹å¼ 2ï¼šæ‰¹é‡æŸ¥è¯¢

```bash
python main.py --mode batch
```

#### æ–¹å¼ 3ï¼šäº¤äº’å¼æ¨¡å¼

```bash
python main.py --mode interactive
```

#### æ–¹å¼ 4ï¼šLangSmith Studio (å¯è§†åŒ–è°ƒè¯•)

```bash
langgraph dev --tunnel
```

ç„¶åè®¿é—®æ˜¾ç¤ºçš„ URL åœ¨ Studio ä¸­å¯è§†åŒ–è°ƒè¯•ã€‚

## åŠŸèƒ½ç‰¹æ€§

### æ”¯æŒçš„åŒ»å­¦å›¾åƒç±»å‹

- ğŸ”¬ **ç—…ç†åˆ‡ç‰‡** (Histopathology)
- ğŸ©» **X-Ray** (èƒ¸ç‰‡ã€éª¨éª¼ç­‰)
- ğŸ§  **CT/MRI** æ‰«æ
- ğŸ«€ **å…¶ä»–åŒ»å­¦æˆåƒ**

### Agent èƒ½åŠ›

1. **å›¾åƒåˆ†æ**
   - ç»„ç»‡ç±»å‹è¯†åˆ«
   - å™¨å®˜ç³»ç»Ÿåˆ†ç±»
   - ç—…ç†ç‰¹å¾æè¿°

2. **æ™ºèƒ½æ¨ç†**
   - ReAct æ¨¡å¼æ¨ç†
   - å·¥å…·è°ƒç”¨å†³ç­–
   - ä¸Šä¸‹æ–‡ç†è§£

3. **å¯è¿½è¸ªæ€§**
   - LangSmith é›†æˆ
   - å®Œæ•´è°ƒç”¨é“¾è¿½è¸ª
   - æ€§èƒ½ç›‘æ§

## ä½¿ç”¨ç¤ºä¾‹

### Python API è°ƒç”¨

```python
from src.agents import create_medical_assistant_agent, run_medical_assistant

# åˆ›å»º agent
agent = create_medical_assistant_agent(
    model_name="gpt-4.1",
    temperature=0.1,
    verbose=True
)

# æé—®
query = """
Analyze the pathology image at 'image.png'. 
What type of tissue is shown and are there any abnormalities?
"""

response = run_medical_assistant(query, agent)
print(response)
```

### å¼‚æ­¥è°ƒç”¨

```python
import asyncio
from src.agents import create_medical_assistant_agent, arun_medical_assistant

async def analyze_images():
    agent = create_medical_assistant_agent()
    
    queries = [
        "Analyze image1.png - what organ is this?",
        "Look at image2.png - is this normal tissue?"
    ]
    
    for query in queries:
        response = await arun_medical_assistant(query, agent)
        print(response)

asyncio.run(analyze_images())
```

### ç›´æ¥ä½¿ç”¨å·¥å…·

```python
from src.tools import medical_vqa_tool

# ç›´æ¥è°ƒç”¨ VQA å·¥å…·ï¼ˆä¸ä½¿ç”¨ agentï¼‰
result = medical_vqa_tool.invoke({
    "image_path": "image.png",
    "question": "What is this tissue?",
    "projector_checkpoint": "projector_epoch2.pt"
})

print(result)
```

## å·¥ä½œæµç¨‹

```mermaid
graph LR
    A[ç”¨æˆ·æé—®] --> B[GPT-4.1 Agent]
    B --> C{éœ€è¦å›¾åƒåˆ†æ?}
    C -->|æ˜¯| D[è°ƒç”¨ medical_vqa_tool]
    D --> E[CLIP è§†è§‰ç¼–ç ]
    E --> F[Projector æŠ•å½±]
    F --> G[TinyLlama ç”Ÿæˆ]
    G --> H[è¿”å›ç­”æ¡ˆ]
    H --> B
    C -->|å¦| I[ç›´æ¥å›ç­”]
    B --> J[æœ€ç»ˆå“åº”]
```

## é«˜çº§åŠŸèƒ½

### 1. è‡ªå®šä¹‰ Prompt

ä¿®æ”¹ `medical_assistant_agent.py` ä¸­çš„ `MEDICAL_ASSISTANT_PROMPT`ã€‚

### 2. æ·»åŠ æ›´å¤šå·¥å…·

```python
from langchain_core.tools import tool

@tool
def custom_medical_tool(input_data: str) -> str:
    """Your custom tool description"""
    # Your implementation
    return result

# åœ¨ create_medical_assistant_agent ä¸­æ·»åŠ 
tools = [medical_vqa_tool, custom_medical_tool]
```

### 3. æ›´æ¢ LLM

```python
agent = create_medical_assistant_agent(
    model_name="gpt-4o",  # æˆ–å…¶ä»–æ¨¡å‹
    temperature=0.2
)
```

## æ€§èƒ½ä¼˜åŒ–

### é¦–æ¬¡åŠ è½½ä¼˜åŒ–

æ¨¡å‹é¦–æ¬¡åŠ è½½éœ€è¦æ—¶é—´ï¼ˆä¸‹è½½ CLIP å’Œ TinyLlamaï¼‰ã€‚åç»­è°ƒç”¨ä¼šä½¿ç”¨ç¼“å­˜ã€‚

### GPU åŠ é€Ÿ

inference.py è‡ªåŠ¨æ£€æµ‹ GPUï¼š
- âœ… æœ‰ GPUï¼šä½¿ç”¨ CUDA
- âš ï¸ æ—  GPUï¼šä½¿ç”¨ CPUï¼ˆè¾ƒæ…¢ï¼‰

### æ‰¹é‡å¤„ç†

ä½¿ç”¨ `--mode batch` æˆ–å¼‚æ­¥ API å¹¶å‘å¤„ç†å¤šä¸ªå›¾åƒã€‚

## æ•…éšœæ’é™¤

### é—®é¢˜ 1: OpenAI API Key é”™è¯¯

```
Error: OpenAI API key not found
```

**è§£å†³**ï¼šç¡®ä¿ `.env` æ–‡ä»¶ä¸­è®¾ç½®äº† `OPENAI_API_KEY`ã€‚

### é—®é¢˜ 2: æ¨¡å‹åŠ è½½å¤±è´¥

```
Error: Projector checkpoint not found
```

**è§£å†³**ï¼šç¡®ä¿ `projector_epoch2.pt` åœ¨é¡¹ç›®æ ¹ç›®å½•ã€‚

### é—®é¢˜ 3: æƒé™é”™è¯¯

```
PermissionError when downloading models
```

**è§£å†³**ï¼šæ£€æŸ¥ HuggingFace ç¼“å­˜ç›®å½•æƒé™ï¼Œæˆ–ä½¿ç”¨ `required_permissions: ['all']`ã€‚

## æ³¨æ„äº‹é¡¹

âš ï¸ **åŒ»ç–—å…è´£å£°æ˜**

æ­¤ç³»ç»Ÿä»…ä¾›ç ”ç©¶å’Œæ•™è‚²ç”¨é€”ã€‚AI åˆ†æç»“æœï¼š
- âŒ **ä¸èƒ½æ›¿ä»£** ä¸“ä¸šåŒ»ç–—è¯Šæ–­
- âŒ **ä¸åº”ç”¨äº** ä¸´åºŠå†³ç­–
- âœ… **åº”ç”±** åˆæ ¼åŒ»ç–—ä¸“ä¸šäººå‘˜éªŒè¯

## æ‰©å±•é˜…è¯»

- [LangChain å®˜æ–¹æ–‡æ¡£](https://docs.langchain.com)
- [LangGraph Studio æŒ‡å—](https://docs.langchain.com/langgraph/studio)
- [ReAct Agent è®ºæ–‡](https://arxiv.org/abs/2210.03629)

## è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## License

MIT License

