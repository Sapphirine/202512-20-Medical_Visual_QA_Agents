{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAxVuxOoAlOS"
   },
   "source": [
    "# **A Simple Notebook Example to Train TinyLlama on UltraMedical Preference Dataset using DPO **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9XiBf59qRfLH",
    "outputId": "6a86cf23-705f-42b0-8cd7-468c0337f2f0"
   },
   "outputs": [],
   "source": [
    "import torch, platform, sys, os, textwrap\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dS56TRFPRh5l",
    "outputId": "658fcb57-f0ae-4785-9ab4-5cf1ad600af6"
   },
   "outputs": [],
   "source": [
    "!pip install -q \"transformers>=4.43.0\" \"datasets>=2.20.0\" \"accelerate>=0.31.0\" \"trl>=0.9.4\" peft\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x66J7I0DRw7d",
    "outputId": "4d8dc27f-ca2d-4dd2-8770-fd41a88020e1"
   },
   "outputs": [],
   "source": [
    "BASE_MODEL = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "PREF_DATASET = \"TsinghuaC3I/UltraMedical-Preference\"\n",
    "\n",
    "OUTPUT_DIR = \"./tinyllama-ultramed-dpo\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Base model:\", BASE_MODEL)\n",
    "print(\"Preference dataset:\", PREF_DATASET)\n",
    "print(\"Output dir:\", OUTPUT_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WuXEsG9kR1TO",
    "outputId": "ae289646-cdd5-405e-f63b-a14f88483ac4"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(PREF_DATASET, split=\"train\")\n",
    "# print(ds)\n",
    "sample = ds[0]\n",
    "sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "013007111c0e4689aef6062acce68fbf",
      "d559f08c103348a69294080e003af7c7",
      "f57b6bba620644cfbe761592e6ccff02",
      "5199ee88ac014a74a714d39a2e1ed88b",
      "8cafd0c89eb04d4f9ab97ca8f6bcda48",
      "b8badb4fc62a475481beb04b6a96ad7f",
      "08bd31c885dd4e55995e885ab0b7bdc9",
      "4b048f2c386d45cba46b3b9ec016b801",
      "334cd1c8bfac4fb281f9d4de5066ee94",
      "2dcd6e6bac414673bc7aef3a9a0855e8",
      "a90586479f8f44dd9cc6ac505a000aee"
     ]
    },
    "id": "8nbCMW9cVtW0",
    "outputId": "4cc18286-4a05-435a-cc78-69132e0f7f5b"
   },
   "outputs": [],
   "source": [
    "def extract_prompt_chosen_rejected(ex):\n",
    "    prompt = ex[\"prompt\"]\n",
    "\n",
    "    def get_last_assistant(turns):\n",
    "        assistants = [t[\"content\"] for t in turns if t[\"role\"] == \"assistant\"]\n",
    "        return assistants[-1] if len(assistants) > 0 else \"\"\n",
    "\n",
    "    chosen_answer = get_last_assistant(ex[\"chosen\"])\n",
    "    rejected_answer = get_last_assistant(ex[\"rejected\"])\n",
    "\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"chosen\": chosen_answer,\n",
    "        \"rejected\": rejected_answer,\n",
    "    }\n",
    "\n",
    "processed_ds = ds.map(extract_prompt_chosen_rejected)\n",
    "processed_ds = processed_ds.remove_columns(\n",
    "    [col for col in processed_ds.column_names if col not in [\"prompt\", \"chosen\", \"rejected\"]]\n",
    ")\n",
    "processed_ds[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275,
     "referenced_widgets": [
      "b42b8f7ab35b40d4a0d6bc550c92f289",
      "85db4554b66a4b9fa9f936edf030643f",
      "f301876f8f2a48a6b895d36f66a03b51",
      "5cfb57992b6f4cac940f578dc18d90a8",
      "38b8155e1ca043ad8dd3b49e4c42e9f8",
      "b5141ae6c15b495e90c39787bd1a6218",
      "d176067d6fb14848865feea719e0ad95",
      "b407f095a9cb4c688b6a285c59b24104",
      "18c084af58304f65a90a634d7d42143b",
      "48857778db564f2b81c91c0c6bab890c",
      "1853ef219f204e9894ec6b541081a204",
      "538a13c0dabf4083adf2755ad4899ecd",
      "341c4f74c7f349388c77c20cd227383f",
      "45ab366a7575434bad6dc8378172cf8d",
      "23ec542fc1cb4850b4f3e6ee72ec2528",
      "4360c99bfb5d46e69924e70cc8a8b7a6",
      "c92d3c705b4d44d6a1d1abdde736deb8",
      "34107651cd0a4937afd8ede59f86b4a5",
      "df96d11e0e8c4aeea763dd8cbcc0c921",
      "8a8a1a2ac2a943a3bef15ca51b97c67a",
      "7c2828c7d0aa4de3972ffbc1e1979e84",
      "8195c0015c3146f298874b6db3d6141b",
      "2df3c4a6c1c24115995075f5f2484a0c",
      "e65743eb9b46406588c5cbeade51981a",
      "74afa80bc99b409da1408fe66483d2d1",
      "f7935daac19e43a6a5d2f3c1ee810c7d",
      "40ddbcdc858c4a82805acc26efaec4a6",
      "6ca33c4e3f0f43bf9140875f14c967e4",
      "e1bc332281294f06a8443ec08e814a10",
      "fd05e224ca9f4c53ad4076f76b861699",
      "a4bc89b244ed4d1abda089dab2f11e1d",
      "cae237b58d6040569d563aad396561c6",
      "c9ecead0cb624570937ba4a693ce08e4",
      "cfeb520058094a7d960b0ea7d3dab39c",
      "e8d15da2336745d8871a68fc884c1947",
      "7616319d88dd4a5d9a334281e1537911",
      "9e41e92ff4f14c72a56f5357b15bcc36",
      "ca8db97aa16d4bcc8acf179f3cb8f0a2",
      "db5719a1b70e4719970b002a53da39f9",
      "7e88edbde2934d95adec08468041630d",
      "e9820ae7ab2842249781df768ed4ee67",
      "7bf3b0b91dbe44ccb03db0b0f8bce5d5",
      "8f14dd8cfe1a4b49ac927da743349a32",
      "11909423fe7d469a986f51b0dd34c269",
      "b87174658bd549d3a78b9cc38c433574",
      "f6ad4d8da99447ce89ec207c03cd5ee0",
      "103887edd1cd485d92c49547e2bdc020",
      "9155043f3a7348a2888ac2afa0c4bb8b",
      "ec918db9d9874f92aa3ea4c9b80dd2c9",
      "72e3d503bc6d436598a37a948b4841fc",
      "6a4e92beadb441bd909ee0d4adcb488e",
      "057b603162304fd2b54c96a810687cff",
      "2bc271890dce4cdaa330ac29aeb8f536",
      "1c8d17ee2b574a5cab48878668140e22",
      "427e38a1940846d483c6aa96797b03e8",
      "c3cf845bcaca42b9923d99feca44a69a",
      "813120924325456596290415ddf15a27",
      "8104b559e51c419d80e8a7fe52822d5e",
      "85b99c8bdfde41f79bb17eb014d4d4fc",
      "a07d5a2fbcd84e09b1ca5898155f4966",
      "ee494cc0cd9d4c55a8b2aac035e19bca",
      "4e2d438324e642379be43a971491a078",
      "f5f88a6de43046a68805d95633d1fca5",
      "f3d05c6e133942299f7bf3c41d2d2b6b",
      "3fec6e78123b4ca1bfcaffba42f02ad8",
      "6f75b2103b564e1a828ddff01f76ddbe",
      "26f638631e6844c5af5577a257286c9b",
      "dace444e0e674fc0a19db4bcc4e60fa3",
      "6a99ab0feaad4846ad2979652a4013f2",
      "ebe6dca732e04904a7f897e64c2971a1",
      "2d0a0e7329814901a1d93bb0226d7844",
      "0e6f709338fc45c9bc0e3e0cba6aed5a",
      "c1c2f9ca06a348119db3b9f94b15ffc7",
      "8b63702eef684021af9eee6f2b044cf9",
      "25fbbd96b0764c2ea6c3d1476c36e9e0",
      "978b1ae5a8f443d3a9d476079725620d",
      "b6d10a220d6849da846135c03c747d4f"
     ]
    },
    "id": "RNPvghQzR3a2",
    "outputId": "4a118c14-6cc4-41ce-fb10-50180b41bde1"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "BASE_MODEL = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "print(\"Model dtype:\", next(model.parameters()).dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NkPE2VMxSHu-",
    "outputId": "2aadcb95-2ea2-4f51-8d8e-e186f92bbaab"
   },
   "outputs": [],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150,
     "referenced_widgets": [
      "4f6a4ee760374bff808795d814884dd3",
      "56c3d81ecb2f4546bc6a9a30b57d65cf",
      "29b64e05d316463a9e9c126ce49b7d36",
      "59a73b2934e449f2954800059f68c684",
      "0b6706220afb457d850300a70e66897b",
      "0c95eb0c79b04e4199a6ff4cf2ce5d75",
      "e3e5ef13cb614262b2439a1e3606e254",
      "842bdf78bf5f4a1c8a4e77082cc5059e",
      "2c885075dbbc41239cce6cc88d760417",
      "edee11e176fe48ba9357d5fda68bc469",
      "6583279b3f8a416c9c7ab2b707b4dfb1",
      "66951cd0d3ac45eba30b2ede3e5d2280",
      "328808e98e8b48c99d65f5b85f5486d2",
      "86061c0d64ba456989efebe509060d99",
      "97bfb7397b994e66858f7501b0fb7432",
      "6f8181264c284a808498aee61b329bc2",
      "90d4e480262f4679a3976593b93223a8",
      "49b6d665e49e4387b31c463995ee2b52",
      "5430e320f67d4d3783e800e816e06d76",
      "12fb51147914465b8b89095cc6f07d21",
      "a83ca9ef9ddf4930b74dd774beef7088",
      "ec4ba14a1a3e4ebf9ce830fb19d89406",
      "c38a01b7768e4f8abe73350a13fdb787",
      "4a4175a8ec5249e69718357b5c66402c",
      "4be94dce9af94593b6c28bc5b2be2bd8",
      "126a910a011543f0b4c667560151de55",
      "eb5d6f2a49674ef3b7933adbd40584ff",
      "710d8a0b7a1c4244bae19d1a0ad9272b",
      "c5c1d8d45f7047b5aa0e2405291a934e",
      "ad535a3ad3dd42d093ac533b6c3a6807",
      "3665f1ee3ee04e12b2b920ac50e33dff",
      "68a9ab2f19d2411683f601e02eec917b",
      "1dadb81ec3a24357b515489a26fb2cf0"
     ]
    },
    "id": "cnVJZrSVR5lD",
    "outputId": "d4b00be6-c99a-4f71-fa48-f7fa930f10dd"
   },
   "outputs": [],
   "source": [
    "from trl import DPOTrainer, DPOConfig\n",
    "\n",
    "OUTPUT_DIR = \"./tinyllama-ultramed-dpo-a100\"\n",
    "\n",
    "training_args = DPOConfig(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=1e-6,\n",
    "    num_train_epochs=1,\n",
    "\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    report_to=\"none\",\n",
    "\n",
    "    bf16=True,\n",
    "    fp16=False,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "\n",
    "    beta=0.1,\n",
    "    max_length=512,\n",
    "    max_prompt_length=512,\n",
    "\n",
    "    remove_unused_columns=False,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "dpo_trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    ref_model=None,\n",
    "    args=training_args,\n",
    "    train_dataset=processed_ds,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8eqR3kpA3Li"
   },
   "source": [
    "Here is just an example; we show actual training result in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4hKKhL4WR8al",
    "outputId": "32c7182a-580f-4b91-f284-0b0f245c970c"
   },
   "outputs": [],
   "source": [
    "dpo_trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pHf0o4mmV0cu",
    "outputId": "174b8dad-1b24-4105-a7d9-e0e9c3c72b34"
   },
   "outputs": [],
   "source": [
    "dpo_trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "\n",
    "print(\"DPO-tuned model saved to:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cEoaDTy5V13s",
    "outputId": "72438c2b-b7b5-40e1-98f0-10c3a7bf76da"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "base_pipe = pipeline(\"text-generation\", model=base_model, tokenizer=base_tokenizer)\n",
    "\n",
    "dpo_tokenizer = AutoTokenizer.from_pretrained(OUTPUT_DIR)\n",
    "dpo_model = AutoModelForCausalLM.from_pretrained(\n",
    "    OUTPUT_DIR,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "dpo_pipe = pipeline(\"text-generation\", model=dpo_model, tokenizer=dpo_tokenizer)\n",
    "\n",
    "example = processed_ds[0]\n",
    "question = example[\"prompt\"]\n",
    "\n",
    "prompt = (\n",
    "    \"You are a helpful and precise medical assistant.\\n\\n\"\n",
    "    f\"Question: {question}\\n\\nAnswer:\"\n",
    ")\n",
    "\n",
    "print(\"=== Base TinyLlama ===\")\n",
    "out_base = base_pipe(prompt, max_new_tokens=256, do_sample=False)\n",
    "print(out_base[0][\"generated_text\"])\n",
    "\n",
    "print(\"\\n=== DPO-tuned TinyLlama ===\")\n",
    "out_dpo = dpo_pipe(prompt, max_new_tokens=256, do_sample=False)\n",
    "print(out_dpo[0][\"generated_text\"])\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
